import requests
import json
import os
import re
import base64
from github import Github
from datetime import datetime

# --- é…ç½® ---
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
REPO_NAME = os.getenv("GITHUB_REPOSITORY")
FILE_JSON = "ip_pool.json"
FILE_TXT = "ips_txt_view.txt"  # æ–°å¢ï¼šæ–¹ä¾¿è§‚å¯Ÿçš„æ–‡æœ¬æ ¼å¼

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8"
}

def extract_ips(text):
    """æœ€å¼ºæ­£åˆ™ï¼šæå– IPv4"""
    return set(re.findall(r'\b(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\b', text))

def fetch_ips():
    all_found = set()
    if not os.path.exists("sources.txt"):
        print("âŒ sources.txt ä¸å­˜åœ¨")
        return []
        
    with open("sources.txt", "r") as f:
        urls = [line.strip() for line in f if line.strip()]

    for url in urls:
        try:
            print(f"ğŸŒ æ­£åœ¨çˆ¬å–: {url}")
            resp = requests.get(url, headers=HEADERS, timeout=15)
            # å°è¯•ç›´æ¥æ­£åˆ™æŠ“å–
            ips = extract_ips(resp.text)
            
            # å¦‚æœæ²¡æŠ“åˆ°ï¼Œå°è¯•å¯¹æ•´ä¸ªé¡µé¢è¿›è¡Œ Base64 è§£ç åå†æŠ“ï¼ˆé’ˆå¯¹æŸäº›åŠ å¯†æºï¼‰
            if not ips:
                try:
                    decoded_text = base64.b64decode(resp.text).decode('utf-8')
                    ips = extract_ips(decoded_text)
                except:
                    pass
            
            if ips:
                all_found.update(ips)
                print(f"âœ… æŠ“å–æˆåŠŸ: è·å¾— {len(ips)} ä¸ª IP")
            else:
                print(f"âš ï¸ æŠ“å–ç»“æœä¸ºç©ºï¼Œé¡µé¢é•¿åº¦: {len(resp.text)}")
        except Exception as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {url} -> {e}")
                
    return sorted(list(all_found))

def update_repo(ips_list):
    if not ips_list:
        print("åœæ­¢æ›´æ–°ï¼šæœ¬æ¬¡æœªè·å–åˆ°ä»»ä½• IP")
        return

    g = Github(GITHUB_TOKEN)
    repo = g.get_repo(REPO_NAME)
    
    # --- 1. æ›´æ–° ip_pool.json (é€»è¾‘åº“) ---
    try:
        contents = repo.get_contents(FILE_JSON)
        db = json.loads(contents.decoded_content.decode())
    except:
        db = {"last_update": "", "pool": {}}

    for ip in ips_list:
        if ip not in db['pool']:
            db['pool'][ip] = {"score": 100, "fail_count": 0, "added_at": datetime.now().strftime("%Y-%m-%d")}
    
    db['last_update'] = datetime.now().strftime("%Y-%m-%d %H:%M")
    json_str = json.dumps(db, indent=2)

    # --- 2. æ›´æ–° ips_txt_view.txt (è§‚å¯Ÿæ¸…å•) ---
    txt_content = f"# å¼¹è¯åº“é¢„è§ˆ (æœ€åæ›´æ–°: {db['last_update']})\n"
    txt_content += f"# æ€»è®¡æ•°é‡: {len(ips_list)}\n\n"
    txt_content += "\n".join(ips_list)

    # --- 3. æäº¤æ›´æ”¹ ---
    print(f"ğŸš€ å‡†å¤‡æäº¤: åº“å†…æ€»æ•° {len(db['pool'])}ï¼Œæœ¬æ¬¡æ–°å¢æ–‡æœ¬é¢„è§ˆ...")
    
    # æäº¤ JSON
    try:
        repo.update_file(FILE_JSON, "Update JSON Pool", json_str, contents.sha)
    except:
        repo.create_file(FILE_JSON, "Create JSON Pool", json_str)

    # æäº¤ TXT (è¦†ç›–æ›´æ–°)
    try:
        txt_file = repo.get_contents(FILE_TXT)
        repo.update_file(FILE_TXT, "Update TXT View", txt_content, txt_file.sha)
    except:
        repo.create_file(FILE_TXT, "Create TXT View", txt_content)
    
    print("ğŸ”¥ GitHub ä»“åº“åŒæ­¥æˆåŠŸï¼")
    print(f"ğŸ” æ ·æ¿æ•°æ® (å‰5ä¸ª): {ips_list[:5]}")

if __name__ == "__main__":
    found_list = fetch_ips()
    update_repo(found_list)
