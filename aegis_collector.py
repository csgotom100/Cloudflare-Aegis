import requests
import json
import os
import re
import time
from github import Github, Auth
from datetime import datetime

# --- é…ç½® ---
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
REPO_NAME = os.getenv("GITHUB_REPOSITORY")
FILE_JSON = "ip_pool.json"
FILE_TXT = "ips_txt_view.txt"

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

def extract_ips(text):
    return set(re.findall(r'\b(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\b', text))

def fetch_ips():
    all_found = set()
    if not os.path.exists("sources.txt"):
        return []
    with open("sources.txt", "r") as f:
        urls = [line.strip() for line in f if line.strip()]
    for url in urls:
        try:
            print(f"ğŸŒ æ­£åœ¨çˆ¬å–: {url}")
            resp = requests.get(url, headers=HEADERS, timeout=15)
            ips = extract_ips(resp.text)
            if ips:
                all_found.update(ips)
                print(f"âœ… æŠ“å–æˆåŠŸ: è·å¾— {len(ips)} ä¸ª IP")
        except Exception as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {url} -> {e}")
    return sorted(list(all_found))

def update_repo(ips_list):
    if not ips_list:
        return

    auth = Auth.Token(GITHUB_TOKEN)
    g = Github(auth=auth)
    repo = g.get_repo(REPO_NAME)
    now_ts = int(time.time())
    
    # 1. è·å–æ—§æ•°æ®
    json_sha = None
    db = {"last_update": "", "pool": {}}
    try:
        contents = repo.get_contents(FILE_JSON)
        db = json.loads(contents.decoded_content.decode())
        json_sha = contents.sha
        if not isinstance(db.get('pool'), dict):
            db['pool'] = {}
    except:
        print(f"â„¹ï¸ åˆ›å»ºæ–°åº“æ–‡ä»¶")

    # 2. é€»è¾‘ Aï¼šå¤„ç†ç¦é—­åˆ°æœŸä¸è§£å° (å¢åŠ å®‰å…¨æ£€æŸ¥)
    for ip, info in list(db['pool'].items()):
        # ä½¿ç”¨ .get(key, default) é˜²æ­¢ KeyError
        ban_until = info.get('ban_until', 0)
        if ban_until > 0 and now_ts > ban_until:
            print(f"âœ¨ IP {ip} ç¦é—­æœŸæ»¡ï¼Œå·²æ¢å¤ã€‚")
            db['pool'][ip]['score'] = 100
            db['pool'][ip]['fail_count'] = 0
            db['pool'][ip]['ban_until'] = 0

    # 3. é€»è¾‘ Bï¼šåˆå¹¶æ–°æŠ“å–çš„ IP
    for ip in ips_list:
        if ip not in db['pool']:
            db['pool'][ip] = {
                "score": 100, 
                "fail_count": 0, 
                "ban_until": 0,
                "added_at": datetime.now().strftime("%Y-%m-%d")
            }
        # ä¿®å¤æ­¤å¤„ï¼šä½¿ç”¨ .get() å®‰å…¨åˆ¤æ–­æ˜¯å¦åœ¨ç¦é—­æœŸ
        elif db['pool'][ip].get('ban_until', 0) == 0:
            db['pool'][ip]['score'] = 100
    
    db['last_update'] = datetime.now().strftime("%Y-%m-%d %H:%M")
    
    # 4. ç”Ÿæˆé¢„è§ˆåˆ—è¡¨ (åªåŒ…å«æ´»è·ƒä¸”æœªç¦é—­çš„ IP)
    active_ips = [ip for ip, info in db['pool'].items() if info.get('ban_until', 0) == 0]
    txt_content = f"# æ´»è·ƒå¼¹è¯åº“ (æ›´æ–°: {db['last_update']})\n# æ€»æ´»è·ƒæ•°: {len(active_ips)}\n\n"
    txt_content += "\n".join(sorted(active_ips))

    # 5. æäº¤
    print(f"ğŸš€ æ­£åœ¨åŒæ­¥è‡³ä»“åº“...")
    json_str = json.dumps(db, indent=2)
    
    if json_sha:
        repo.update_file(FILE_JSON, "Collector Sync", json_str, json_sha)
    else:
        repo.create_file(FILE_JSON, "Collector Init", json_str)

    try:
        txt_file = repo.get_contents(FILE_TXT)
        repo.update_file(FILE_TXT, "Update View", txt_content, txt_file.sha)
    except:
        repo.create_file(FILE_TXT, "Create View", txt_content)
    
    print(f"ğŸ”¥ å®Œæˆï¼å½“å‰æ´»è·ƒ IP: {len(active_ips)}")

if __name__ == "__main__":
    found_list = fetch_ips()
    update_repo(found_list)
